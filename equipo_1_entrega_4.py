# -*- coding: utf-8 -*-
"""Equipo_1_Entrega_4

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q4FkYxxsxFO72e_BUy9vW8vNWRde2LQ9

# **Análisis del riesgo financiero en base a las estimaciones futuras del valor de las acciones de Tesla**
Agustín Gustavo Chamorro Carrizo,
Patricio Ignacio Mercado Urizar,
Gaspar Alonso Merino González.


A continuación, se presentará el modelo realizado por el grupo para predecir los valores futuros para las acciones de una empresa, en este caso, Tesla. Para lo anterior se utilizó el modelo ARIMA. Este modelo, o media móvil integrada autorregresiva, es una técnica que se utiliza con el objetivo de analizar series temporales, pronosticando posibles valores futuros de la misma serie temporal. Se utiliza este método en el ámbito del Forecasting, el cual es una rama del machine learning que en base a los datos almacenados del pasado, predice los valores futuros. El ARIMA, se utiliza en dos enfoques principales a la hora de querer hacer FORECASTING, el primer caso, no se considera la estacionalidad (relación de dependencia con respecto a un periodo de tiempo concreto) donde se busca prever el futuro con la base de datos del pasado, mientras que en el segundo caso si se considera la estacionalidad, ya sea en periodos de días, semanas o meses, este ultimo es el que finalmente se decidió usar para el proyecto.
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import files
from statsmodels.tsa.seasonal import seasonal_decompose
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

"""Se utilizo este segmento de codigo para importar las librerias que se ocuparon para la realización del modelo"""

# Upload and load the data
uploaded = files.upload()
df = pd.read_csv('Tesla_Stock_Updated_V2.csv', index_col="Date", parse_dates=True)

# Initial data inspection
df.head()

df.info()

"""La información del dataset entrega 4 columnas de datos de tipo float, 1  columna de tipo integer y 1 columna de tipo objeto. De los atributos presentados en el dataset solamente "Date" es de tipo Intervalo, mientras que los otros 5 son de Razón"""

df.isnull().sum()

"""No existen casillas nulas dentro del dataset"""

df.describe().T

df = df.drop('Unnamed: 0', axis=1)
plt.figure(figsize=(8,6))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
plt.title('Matriz de Correlación')
plt.show()

"""Como se puede apreciar los atributos Open, High, Low y Close presentan una correlación máxima o perfecta, esto es bastante esperable, debido a que estos atributos están vinculados por naturaleza. Si el precio de apertura fuese alto, es bastante probable que los precios máximo, mínimo y de cierre tambien lo sean, ya que se encuentran dentro de un mismo período de negociación. Esto lleva a determinar que existe una redundancia en los datos, debido a la similitud en la tendencia, por lo que se optará por reducir la dimensionalidad, utilizando como atributo principal el precio de cierre ("Close"). Por otro lado, el atributo Volume posee una baja correlación con los demás atributos del dataset, lo cual puede llevar a la conclusión que la cantidad de acciones transadas en un período de tiempo está determinado por factores externos al precio de estas."""

cont_cols = list(df.columns)
for col in cont_cols:
    print(col)
    print('Skew :',round(df[col].skew(),2))
    plt.figure(figsize=(15,4))
    plt.subplot(1,2,1)
    df[col].hist(bins=10, grid=False)
    plt.ylabel('count')
    plt.subplot(1,2,2)
    sns.boxplot(x=df[col])
    plt.show()

"""Podemos observar que todos los atributos muestran una asimetría positiva (skew = 0.81), lo que indica que en cada uno de ellos, la mayoría de los precios de las acciones se encuentran en los rangos bajos, pero hay valores extremos más altos, lo que genera una cola larga hacia la derecha. Esto sugiere que aunque las acciones de Tesla se cotizan con frecuencia en precios bajos, ha habido periodos en los que los precios han alcanzado valores significativamente altos. Por otro lado en el atributo de Volume podemos observar que el volumen de negociacion suele ser moderado pero tiene ciertos picos importantes en los que el volumen ha aumentado drásticamente probablemente debido a factores externos o eventos significativos de la empresa o el mercado, para estar seguros se debería realizar una investigacion al respecto."""

df = df.reset_index()

df["Date"] = pd.to_datetime(df["Date"])
plt.figure(figsize=(12,6))
plt.plot(df['Date'], df['Close'], label='Precio de Cierre')
plt.title('Evolución del Precio de Cierre')
plt.xlabel('Fecha')
plt.ylabel('Precio de Cierre')
plt.legend()
plt.show()

# Commented out IPython magic to ensure Python compatibility.
# %pip install pmdarima

serie = df['Close']

from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.stattools import adfuller
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

result = adfuller(serie)

"""Se verifica la estacionariedad de los datos en base a la prueba Dickey-Fuller aumentada. Que los datos sean estacionarios significa que sus propiedades estadísticas, como la media, la varianza y la autocorrelación, son constantes a lo largo del tiempo. A continuación se realiza prueba de hipótesis para la verificación del supuesto.
Donde:
H0: La serie temporal no es estacionaria (tiene una raíz unitaria)
H1: La serie temporal es estacionaria (no tiene raiz unitaria)
"""

print('ADF Statistic: %f' % result[0])
print('p-value: %f' % result[1])
print('Lags Used: %d' % result[2])
print('Number of Observations Used: %d' % result[3])
print('Critical Values:')
for key, value in result[4].items():
    print('\t%s: %.3f' % (key, value))

"""No se rechaza la H0, es decir, no hay evidencia suficiente para concluir que la serie temporal es estacionaria (p-value > 0,05). En base a esto se utiliza la diferencia entre los valores de cierre (serie.diff()) para asegurar estacionariedad, y además, se eliminan los datos Nulos (.dropna()), ya que se genera uno al realizar la primera diferencia entre los valores."""

data_diff = serie.diff().dropna()
result = adfuller(data_diff)

print('ADF Statistic: %f' % result[0])
print('p-value: %f' % result[1])
print('Lags Used: %d' % result[2])
print('Number of Observations Used: %d' % result[3])
print('Critical Values:')

for key, value in result[4].items():
  print('\t%s: %.3f' % (key, value))

"""Ahora existe evidencia suficiente para concluir que la serie temporal es estacionaria (p-value <  0,05)."""

plot_acf(data_diff, lags=30)
plt.title('Autocorrelation Function (ACF)')
plt.xlabel('Lag')
plt.ylabel('Autocorrelation')
plt.show()

plot_pacf(data_diff, lags=30)
plt.title('Partial Autocorrelation Function (PACF)')
plt.xlabel('Lag')
plt.ylabel('Partial Autocorrelation')
plt.show()

"""En base a los gráficos presentados (ACF y PACF), al existir un peak en el lag 1 lse sugiere que los parámetros del modelo ARIMA debiesen ser p = 1, d = 1 y q = 1"""

result = seasonal_decompose(serie, model='multiplicative', period = 30)
fig = plt.figure()
fig = result.plot()
fig.set_size_inches(16, 9)

"""En base a los gráficos anteriores, se puede verificar el supuesto de linealidad de los valores de la serie temporal. Se procede con la implementación del modelo ARIMA."""

train_size = len(data_diff) - 30
train, test = data_diff[:train_size], data_diff[train_size:]

p, d, q = 1, 1, 1
model = ARIMA(train, order=(p, d, q))
model_fit = model.fit()

forecast = model_fit.forecast(steps=len(test))

forecast_index = test.index
forecast_series = pd.Series(forecast.values, index=test.index)

"""Se utiliza el modelo ARIMA entrenado para generar predicciones para los periodos futuros representados por los datos de prueba. Luego, organizan estas predicciones en una Serie de Pandas (forecast_series) con el índice de tiempo correcto, lo que facilita la comparación y el análisis de los valores pronosticados frente a los valores reales en el conjunto de datos de prueba"""

mse = mean_squared_error(test, forecast_series)
mae = mean_absolute_error(test, forecast_series)
rmse = np.sqrt(mse)
mape = np.mean(np.abs((test - forecast_series) / test)) * 100
r2 = r2_score(test, forecast_series)

print(f'Error Cuadrático Medio (MSE): {mse}')
print(f'Error Absoluto Medio (MAE): {mae}')
print(f'Raiz del Error Cuadrático Medio (RMSE): {rmse}')
print(f'Error Porcentual Absoluto Medio (MAPE): {mape}%')
print(f'Coeficiente de Determinación (R²): {r2}')

"""Para poder determinar como rinde el modelo ARIMA se calculan diferentes metricas de error, escencialmente queremos observar que tan cercano son los valores predecidos en comparacion con los valores reales. Observando los resultados de estas metricas pudimos llegar a la conclusion que nuestro modelo no esta capturando de manera adecuada todos los patrones en los datos de las acciones de Tesla. Esto se puede atribuir a diferentes razones pero como equipo concluimos que algunas de las razones pueden ser que a pesar de la diferenciacion es posible que los datos todavía contengan tendencias no capturadas o dado que sas acciones de Tesla al depender de múltiples factores externos, como noticias, eventos económicos o indicadores adicionales, que un modelo ARIMA no puede capturar.


"""

plt.figure(figsize=(14, 5))
plt.plot(train.index[-100:], train[-100:], label='Datos de entrenamiento')
plt.plot(test.index, test, color='gray', label='Valores reales o de testeo')
plt.plot(forecast_series.index, forecast_series, color='blue', label='Predicciones')
plt.legend()
plt.title('Predicción vs Valores reales')
plt.xlabel('Fecha')
plt.ylabel('Precio de Cierre (Data diferenciada)')
plt.show()

"""Este código genera una visualización comparativa que permite evaluar el desempeño del modelo ARIMA al predecir valores futuros. Primero, se grafican los últimos 100 puntos de los datos de entrenamiento de la fecha,
para dar contexto sobre los valores históricos que el modelo utilizó para aprender. Luego, se incluyen los valores reales del conjunto de prueba, representados en color gris, que son los datos contra los que se evaluará el modelo. Finalmente, se grafican las predicciones generadas por el modelo ARIMA, representadas en color azul, y se alinean temporalmente con los valores reales mediante el índice de tiempo. La gráfica incorpora una leyenda que identifica claramente los datos de entrenamiento, los valores reales y las predicciones, junto con un título descriptivo y etiquetas para los ejes que explican que los datos corresponden al precio de cierre en una escala diferenciada. Esta visualización es clave para identificar visualmente si el modelo ARIMA es capaz de capturar los patrones en los datos y qué tan bien pronostica valores futuros al compararlos con los datos reales del conjunto de prueba.
"""

train_size = len(data_diff) - 30
train, test = data_diff[:train_size], data_diff[train_size:]

p, d, q = 10, 2, 3
model = ARIMA(train, order=(p, d, q))
model_fit = model.fit()

"""Este código divide los datos en conjuntos de entrenamiento y prueba, configura el modelo con parámetros específicos y ajusta el modelo utilizando los datos de entrenamiento. Primero, calcula el tamaño del conjunto de entrenamiento, dejando los últimos 30 puntos de los datos diferenciados, data_diff, para el conjunto de prueba. Los datos se dividen en train, que contiene los primeros N-30 puntos, y test, que incluye los últimos 30 puntos que se usarán para evaluar el modelo. Luego, se definen los parámetros del modelo: p = 10 (número de términos autoregresivos),
d=2 (número de diferenciaciones para lograr estacionariedad) y
q=3 (número de términos de media móvil). Con estos parámetros, se crea un modelo ARIMA que se ajusta únicamente al conjunto de datos de entrenamiento mediante el método fit. Este ajuste calcula los coeficientes del modelo y establece la mejor configuración para describir los patrones en los datos de entrenamiento. Finalmente, el modelo ajustado model_fit está listo para realizar predicciones o evaluaciones basadas en los datos de prueba.







"""

forecast = model_fit.forecast(steps=len(test))

forecast_index = test.index
forecast_series = pd.Series(forecast.values, index=test.index)

mse = mean_squared_error(test, forecast_series)
mae = mean_absolute_error(test, forecast_series)
rmse = np.sqrt(mse)
mape = np.mean(np.abs((test - forecast_series) / test)) * 100
r2 = r2_score(test, forecast_series)

print(f'Error Cuadrático Medio (MSE): {mse}')
print(f'Error Absoluto Medio (MAE): {mae}')
print(f'Raiz del Error Cuadrático Medio (RMSE): {rmse}')
print(f'Error Porcentual Absoluto Medio (MAPE): {mape}%')
print(f'Coeficiente de Determinación (R²): {r2}')

"""Esta parte del código evalúa la precisión del modelo ARIMA al predecir los precios de las acciones de Tesla, comparando las predicciones con los valores reales. Se utilizan métricas como el MSE, MAE y MAPE para medir la magnitud de los errores, mientras que el R2 indica qué tan bien el modelo explica la variabilidad de los datos. Estas métricas permiten obtener una visión clara del desempeño del modelo, tras haber obtenido los resultados podemos concluir que de estos valores indican que el modelo tiene dificultades para predecir con precisión el comportamiento de las acciones de Tesla, reflejado especialmente en el alto MAPE y el valor negativo del R2 , que sugiere que el modelo no explica adecuadamente la variabilidad de los datos. Este análisis resalta la necesidad de ajustar los parámetros del modelo o explorar alternativas para mejorar su capacidad predictiva."""

plt.figure(figsize=(14, 5))
plt.plot(train.index[-100:], train[-100:], label='Datos de entrenamiento')
plt.plot(test.index, test, color='gray', label='Valores reales o de testeo')
plt.plot(forecast_series.index, forecast_series, color='blue', label='Predicciones')
plt.legend()
plt.title('Predicción vs Valores reales')
plt.xlabel('Fecha')
plt.ylabel('Precio de Cierre')
plt.show()

"""Gráfico última predicción lograda por el grupo"""